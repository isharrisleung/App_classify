{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict={'14783134 15697333 14854817 14925479':0,'14847385 14844587 14848641 14847398':1, \\\n",
    "#      '14786237 15697082 14722731 14924977':2, '14844093 15705739 14854331 15699885':3, \\\n",
    "#      '15632285 15706536 14721977 14925219':4, '15630486 15702410 14718849 15709093':5, \\\n",
    "#      '14924216 14781104 14717848 14791612':6, '14782903 15634620 15638402 15706300':7, \\\n",
    "#     '14858934 15636660 15704193 14849963':8, '15709098 14716590 14924703 14779559':9, \\\n",
    "#      '14726332 14728344 14854542 14844591':10,'14856354 14844592':11, \\\n",
    "#      '15710359 14847407 14845602 14859696':12, '14794687 14782344':13, \\\n",
    "#      '14925756 15639967 14853254 14728639':14, '14844593 14924945':15, \\\n",
    "#     '14844856 14724258 14925237 14854807':16, '14852788 14717848 15639958 15632020':17, \\\n",
    "#      '14784131 14858934 14784131 14845064':18}\n",
    "\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "# import gc\n",
    "\n",
    "# print('loading datasets......')\n",
    "# train_data = pd.read_csv('./data/train.csv')\n",
    "# new_label = []\n",
    "# for i in range(len(train_data)):\n",
    "#      new_label.append(label_dict[train_data.loc[i][\"label\"]])\n",
    "\n",
    "# train_data[\"new_label\"] = new_label\n",
    "# train_data.to_csv(\"./data/new_train_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "# handle raw data\n",
    "\n",
    "print('loading datasets......')\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print('{} lines in train datasets'.format(len(train_data)))\n",
    "print('{} lines in test datasets'.format(len(test_data)))\n",
    "\n",
    "all_text = []\n",
    "\n",
    "for row in range(len(train_data)):\n",
    "    all_text.append(train_data.loc[row][\"name\"].split())\n",
    "    all_text.append(train_data.loc[row][\"description\"].split())\n",
    "\n",
    "for row in range(len(test_data)):\n",
    "    all_text.append(test_data.loc[row][\"name\"].split())\n",
    "    all_text.append(test_data.loc[row][\"description\"].split())\n",
    "\n",
    "with open(\"./data/raw_text.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "embed_size = 100\n",
    "window = 4\n",
    "min_count = 1\n",
    "\n",
    "model = Word2Vec(all_text, vector_size=embed_size, window=window, min_count=min_count, workers=4)\n",
    "model.wv.save_word2vec_format(\"./data/wordvec_embsize_{}_window_{}_mincount_{}.bin\".format(embed_size, window, min_count), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec, KeyedVectors\n",
    "embedding_model = KeyedVectors.load_word2vec_format(\"./data/wordvec_embsize_100_window_4_mincount_3.bin\", binary=True).key_to_index\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"./data/new_train_data.csv\")\n",
    "new_train = pd.DataFrame(columns=[\"name\", \"description\", \"new_label\"])\n",
    "for i in range(len(train_data)):\n",
    "    flag = 0\n",
    "    for name in train_data.iloc[i][\"name\"].split():\n",
    "        if name in embedding_model:\n",
    "            flag += 1\n",
    "            break\n",
    "    \n",
    "    for desc in train_data.iloc[i][\"description\"].split():\n",
    "        if desc in embedding_model:\n",
    "            flag += 1\n",
    "            break\n",
    "    if flag == 2:\n",
    "        print(\"sadas\")\n",
    "        new_train.append(train_data.iloc[i][[\"name\", \"description\", \"new_label\"]], ignore_index = True)\n",
    "new_train.to_csv(\"./data/new_new_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71342f419acc3ba6ae382518c4ba2a9e6f9bd8751a76a463bc8e77674675b221"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
